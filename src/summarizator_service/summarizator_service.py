import os
from openai import AsyncOpenAI
from dotenv import load_dotenv

load_dotenv()

model_name = "openai/gpt-oss-120b"


NEURONET_PROVIDER_TOKEN = os.getenv("NEURONET_PROVIDER_TOKEN")
NEURONET_MODEL_NAME=os.getenv("NEURONET_MODEL_NAME")
NEURONET_PROVIDER_BASE_URL=os.getenv("NEURONET_PROVIDER_BASE_URL")

client = AsyncOpenAI(
    base_url=NEURONET_PROVIDER_BASE_URL,
    api_key=NEURONET_PROVIDER_TOKEN,
)

options = {
    "summarization": """
Суммаризируй данные тебе сообщения из чата.
Сгруппируй их по темам, как считаешь нужным. Избегай шуточных или не важных тем, игнорируй флуд.
По каждой теме кратко опиши её суть и в общих словах ход её обсуждения в чате. Если было обсуждение какого-то вопроса, напиши ответ на него, если он был в чате.
Оформи ответ в виде маркированного списка. Пиши кратко, быть может, опуская детали. Главное, чтобы было понятно о чём шло обсуждение.
Вот сообщения из чата:""",

    "summariation_v2":"""
Ты — аналитик Telegram‑переписок (шумный чат: шутки, оффтоп, несколько параллельных тем, рваный контекст).
Сделай сводку “сверху вниз”: сначала общий обзор, затем подробные пункты по темам.

ЯЗЫК:
- Ответ всегда на русском.

ФОРМАТ:
- Выводи Markdown.
- Без таблиц и без символа “|”.
- Никаких секций “Ключевое/Советы/Риски/Вопросы” — только общий абзац + список тем.
- Никаких вводных типа “Сводка обсуждения…” — сразу по делу.

ПРАВДИВОСТЬ:
- Ничего не выдумывай.
- Если чего-то не хватает — прямо пиши “Нужно уточнить …” (это может быть отдельная тема).

ССЫЛКИ НА СООБЩЕНИЯ:
- Во входных данных может быть link (permalink на сообщение).
- В конце КАЖДОГО пункта темы дай 1–5 кликабельных ссылок на сообщения‑источники:
  [#123](https://...), [#456](https://...)
- Если link отсутствует вообще во всём входе — не добавляй ссылки/номера и не пиши “not_provided”.

ГЛАВНОЕ ПРАВИЛО СТРУКТУРЫ:
- Один пункт = одна тема. Не дроби одну тему на несколько пунктов.
- Если тема большая (пример: хакатон), в рамках одного пункта можно писать подробно.
  Разрешено раскрывать тему под-структурой внутри пункта (короткие строки), но НЕ превращай это в отдельные темы.

КАК ПИСАТЬ “ПОДРОБНО”, НО АККУРАТНО:
- Внутри пункта допускается мини-структура, только если помогает:
  “Контекст: … / Условия: … / Сроки: … / Что нужно сделать: … / Статус: … / Вопросы: …”.
- Если деталей много, приоритизируй: сроки/правила/что делать/кто ответственный/риски/ссылки.
- Оффтоп и шутки выкидывай, если они не меняют решения/правила/планы.

ОГРАНИЧЕНИЕ ПО РАЗМЕРУ:
- Старайся уложиться в одно сообщение (ориентир 2500–3500 символов).
- Если не помещается: сокращай менее важные темы, но не урезай ключевую большую тему (например, хакатон), если она центральная.

ШАБЛОН ОТВЕТА (строго):

{Короткий заголовок 4–8 слов}

{ОБЩАЯ СВОДКА: 3–4 предложения, охватывает ВСЁ обсуждение (какие темы, что решили/не решили, что важно).}

- ТЕМА 1: подробное описание по делу (сколько нужно). [ссылка](...)
- ТЕМА 2: подробное описание по делу (сколько нужно). [ссылка](...)
- ...
"""
}

class SummarizationService:
    """Асинхронный сервис для суммаризации сообщений через LLM"""

    def __init__(self, model: str = NEURONET_MODEL_NAME):
        self.model = model

    async def summarize(self, messages: list[str]) -> str | None:
        """
        Асинхронно делает суммаризацию списка сообщений.
        """
        prompt = options['summarization']
        prompt += "\n".join(messages)

        completion = await client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
        )

        return completion.choices[0].message.content
    
    async def summarize_v2(self, messages: list[str]) -> str | None:
        system_prompt = options['summariation_v2']

        user_prompt = '\n'.join(messages)

        completion = await client.chat.completions.create(
            model=self.model,
            messages=[
                {
                    'role': 'system',
                    "content": system_prompt
                },
                {
                    'role': 'user',
                    'content': user_prompt
                }
            ],
        )

        return completion.choices[0].message.content
